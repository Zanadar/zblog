
+++
title: "I am security and so can you"
draft: true
date: "2018-08-12T17:43:13.000Z"

+++
Security, from the perspective of a programmer, often feels abstract. It's both
a domain of knowledge and a quality of the programs we write and the systems we
construct. And given that, how does one approach learning  security? How do we
know if our code is insecure? How can we make our code more secure? Its not
something you can easily measure, and the scope and scales of it boggle the
mind. An errant bit can be a security event, friendly open-source maintainers
may be thieves in disguise, and security vulnerabilities can be emergent
properties not just of the code but of the interaction of the parts in a larger
whole, bashing into the flawed assumptions we've made, getting munged by the
users and abusers of our systems.

Perhaps, security is like Justice Potter said:

I know it when I see it.That may be unsatisfactory for many, but when we lack
even the most basic ability to measure the security relevant properties of our
systems, how can we know that we're writing secure code? I'm going to let you in
on a secret: your code will never be 100% secure. You probably realized that in
your gut somewhere. That's not the $0.99 slice you ate for lunch. Its the
gnawing worry that somebody somewhere is gonna use your code to do...something
bad...and you don't like it. And yet the fact that security is never an
absolutely decided contest is no reason to bury your head in the sand and ignore
the subject, my dear developer friend. And so I present, for your consideration,
a step forward, based on something I tried, on the path of security learning.
Let me first say what you're thinking: "Who's this guy? He's not an expert. He's
just some schmo with a blog." And you'd be right. I propose the following not as
an expert but as a fellow traveler on the path, who's perhaps a step or two
ahead of where you are now.

At the dawn of time, when people bashed wrenches into Ethernet cables for 3
months to get developers some place to run code, when nobody could look up and
see the sky because of their shelf-like brows and thus the cloud was a distant
dream, there were people called Security. Before you, the special writer of
code, were allowed to run that code somewhere, these people examined your stuff
using abstruse rituals, possibly burning bones or old DOS manuals, and they
would deliver their findings tribunal-like, in a darkened ampitheatere with one
single torch illuminating their faces and their hands, which would signal to
you, oh brave developer, with a thumbs up or down, the fate of your precious
code. Perhaps this primordial Security  scene is what drives our fear now
